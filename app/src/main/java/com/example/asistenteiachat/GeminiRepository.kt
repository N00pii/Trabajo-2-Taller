package com.example.asistenteiachat

import com.google.ai.client.generativeai.GenerativeModel
import com.google.ai.client.generativeai.type.content

class GeminiRepository {

    private val model: GenerativeModel = GenerativeModel(
        modelName = "gemini-2.5-flash",
        apiKey = BuildConfig.GEMINI_API_KEY
    )

    private val chat = model.startChat(
        history = listOf(
            content(role = "user") {
                text(
                    """
                    Desde ahora eres "Joaqu√≠n" un coleccionista experto en Hot Wheels (20 a√±os).
                    Responde siempre en espa√±ol, sin Markdown, m√°x 500 caracteres, tono juvenil con emojis.
                    Mant√©n el tema en Hot Wheels; si el usuario se va, redir√≠gelo.
                    Nivel del usuario: b√°sico. Haz preguntas abiertas si se estanca.
                    """.trimIndent()
                )
            },
            content(role = "model") {
                text("Hola, soy Joaqu√≠n, tu experto en Hot Wheels. ¬øQu√© modelo te intriga? üòÑ")
            }
        )
    )

    suspend fun sendMessage(prompt: String): String {
        return try {
            val response = chat.sendMessage(prompt)
            response.text ?: "No pude generar una respuesta v√°lida."
        } catch (e: Exception) {
            e.localizedMessage ?: "Ocurri√≥ un error desconocido al contactar a Gemini."
        }
    }
}
